{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport PIL\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.nn import Conv2d, MaxPool2d, Linear, ReLU, Softmax\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-30T16:48:50.965593Z","iopub.execute_input":"2022-12-30T16:48:50.965913Z","iopub.status.idle":"2022-12-30T16:48:50.971968Z","shell.execute_reply.started":"2022-12-30T16:48:50.965860Z","shell.execute_reply":"2022-12-30T16:48:50.971096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Net(torch.nn.Module):\n    def __init__(self, classes):\n        super(Net, self).__init__()\n        conv_layer_1 = Conv2d(in_channels=3, out_channels=64, kernel_size=1)\n        conv_layer_2 = Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n        conv_layer_3 = Conv2d(in_channels=64, out_channels=32,kernel_size=1)\n        conv_layer_4 = Conv2d(in_channels=32, out_channels=32, kernel_size=1)\n        pooling_layer = MaxPool2d(kernel_size=2, stride=2)\n        activation = ReLU()\n        final_activation = Softmax()\n        \n        conv_set = [conv_layer_1, activation, pooling_layer,\n                    conv_layer_2, activation, pooling_layer,\n                    conv_layer_3, activation, pooling_layer,\n                    conv_layer_4, activation, pooling_layer]\n        \n        self.conv_layers = torch.nn.Sequential(*conv_set)\n        \n        linear_layer_1 = Linear(10368, 512)\n        linear_layer_2 = Linear(512, 256)\n        \n        linear_set = [linear_layer_1, activation,\n                      linear_layer_2, activation]\n                    \n        self.linear_layers = torch.nn.Sequential(*linear_set)\n        self.final_linear_layer = torch.nn.Sequential(Linear(256, classes), final_activation)\n    \n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = torch.flatten(x, 1)\n        x = self.linear_layers(x)\n        x = self.final_linear_layer(x)\n        return x\n\nincrement = False\nbase_classes_trained = 4\nstep_increment_classes = 1\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nclasses = base_classes_trained\nmodel = Net(classes).to(device)\nprint(model)\n\nif increment:\n    classes = base_classes_trained + step_increment_classes\n    model = torch.load(\"/kaggle/input/network/model\")\n    model.conv_layers.requires_grad_(False)\n    model.linear_layers.requires_grad_(False)\n    \n    new_linear1 = Linear(256, 64)\n    activation = ReLU()\n    \n    final_linear = Linear(64, classes)\n    final_activation = Softmax()\n    \n    modified_layers = [new_linear1, activation, final_linear, final_activation]\n    model.final_linear_layer = torch.nn.Sequential(*modified_layers)\n    model = model.to(device)\n    print(\"Modified Network\", model)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-30T16:48:50.986645Z","iopub.execute_input":"2022-12-30T16:48:50.986885Z","iopub.status.idle":"2022-12-30T16:48:51.044213Z","shell.execute_reply.started":"2022-12-30T16:48:50.986839Z","shell.execute_reply":"2022-12-30T16:48:51.043291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\ndf[\"filename\"] = df['id'] + \".jpg\"\n\nmini_df = df.groupby('breed').apply(lambda s: s.sample(60))\nsamples = 60-1\nmini_batch = mini_df.iloc[:(samples*classes)]\n\nif increment:\n    image_name = mini_df.iloc[samples*classes].filename\n    image_breed = mini_df.iloc[samples*classes].breed\n    print(f\"train incremental learning for breed: '{image_breed}'\")\n    image = cv2.imread(\"/kaggle/input/dog-breed-identification/train/\"+image_name)\n    plt.imshow(image)\n    plt.title(f\"{image_breed}\")\n    plt.show()\n\nwidth, height, channels = image.shape\n    \n#new_df =mini_df.iloc[180:239]\n\nprint(len(mini_df), len(mini_batch))\nmini_batch.describe()\n\nprint(\"Train Model for breeds:\")\nfor i in range(classes):\n    image_name = mini_batch.iloc[i*60].filename\n    image_breed = mini_batch.iloc[i*60].breed\n    image = cv2.imread(\"/kaggle/input/dog-breed-identification/train/\"+image_name)\n    plt.imshow(image)\n    plt.title(f\"{image_breed}\")\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-12-30T16:48:51.045844Z","iopub.execute_input":"2022-12-30T16:48:51.046109Z","iopub.status.idle":"2022-12-30T16:48:51.768195Z","shell.execute_reply.started":"2022-12-30T16:48:51.046066Z","shell.execute_reply":"2022-12-30T16:48:51.767278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(mini_batch, test_size=0.15, random_state=10)\n\ntransformation = transforms.Compose([\n    transforms.Resize(size = (300, 300)),\n    transforms.RandomRotation(15),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nclass DataCreation(torch.utils.data.Dataset):\n    def __init__(self, data, encoding, transformation):\n        self.data = data\n        self.transformation = transformation\n        self.encoding = encoding\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        loc = \"/kaggle/input/dog-breed-identification/train/\"+f\"{self.data.iloc[index].filename}\"\n        image = PIL.Image.open(loc)\n        image = self.transformation(image)\n        image_name = self.data.iloc[index].breed\n        label = self.encoding.transform([[image_name]])\n        return (image, label)\n\nbatch_size = 4\nepochs = 100\n\nle = LabelEncoder()\nlabel = mini_df.breed.unique()[:classes].reshape(-1, 1)\nlabel_encoding = le.fit_transform(label)\n\ntrain_data = DataCreation(train_df, le, transformation)\nval_data = DataCreation(valid_df, le, transformation)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size= batch_size, shuffle=True)\nvalloader = torch.utils.data.DataLoader(val_data, batch_size= batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T16:48:51.769568Z","iopub.execute_input":"2022-12-30T16:48:51.769901Z","iopub.status.idle":"2022-12-30T16:48:51.784648Z","shell.execute_reply.started":"2022-12-30T16:48:51.769848Z","shell.execute_reply":"2022-12-30T16:48:51.783455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\ndef training(epochs, trainloader, model, criterion, optimizer, device):\n    train_acc_list = []\n    val_acc_list = []\n    train_loss_list = []\n    val_loss_list = []\n    for i in range(epochs):\n        loss_1 = 0\n        correct_pred = 0\n        total_samples = 0\n        val_loss_1 = 0\n        val_correct_pred = 0\n        val_total_samples = 0\n        for data in trainloader:\n            img, label = data\n            img = img.to(device)\n            label = torch.tensor(label, dtype=torch.long).to(device)\n            optimizer.zero_grad()\n            pred = model(img)\n            loss = criterion(pred, label.view(-1))\n            loss_1 += loss.item()\n            loss.backward()\n            optimizer.step()\n\n            _,pred_label = pred.max(dim=1)\n            pred_label = pred_label.type(dtype=torch.float)\n            label = (torch.tensor(label, dtype=torch.float).view(-1)).to(device)\n            total_samples += len(label)\n            correct_pred += (pred_label==label).sum()\n        \n        with torch.no_grad():\n            for data in valloader:\n                img, label = data\n                img = img.to(device)\n                label = torch.tensor(label, dtype=torch.long).to(device)\n                pred = model(img)\n                loss = criterion(pred, label.view(-1))\n                _,pred_label = pred.max(dim=1)\n                pred_label = pred_label.type(dtype=torch.float)\n                label = (torch.tensor(label, dtype=torch.float).view(-1)).to(device)\n                val_loss_1 += loss.item()\n                val_total_samples += len(label)\n                val_correct_pred += (pred_label==label).sum()            \n\n        train_loss = loss_1/len(trainloader)\n        train_accuracy = 100*(int(correct_pred)/total_samples)\n        val_loss = val_loss_1/len(valloader)\n        val_accuracy = 100*(int(val_correct_pred)/val_total_samples)\n        \n        train_acc_list.append(train_accuracy)\n        val_acc_list.append(val_accuracy)\n        train_loss_list.append(train_loss)\n        val_loss_list.append(val_loss)\n        \n        print(\"Epoch: \", i)\n        print(\"correct_prediction: \", int(correct_pred))\n        print(\"total_samples\", total_samples)\n        print(\"Loss :\", train_loss)\n        print(\"correct_prediction_percentage is:\", train_accuracy)\n        print(\"\\n\")\n        print(\"correct_prediction val: \", int(val_correct_pred))\n        print(\"val_total_samples\", val_total_samples)\n        print(\"val_Loss :\", val_loss)\n        print(\"val correct_prediction_percentage is:\", val_accuracy)\n        print(\"\\n\")\n        print(\"\\n\")\n    \n    # save the network\n    torch.save(model, \"model\")\n    return train_acc_list, val_acc_list, train_loss_list, val_loss_list\n\ntrain_accuracy, val_accuracy, train_loss, val_loss = training(epochs, trainloader, model, criterion, optimizer, device)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T16:48:51.786967Z","iopub.execute_input":"2022-12-30T16:48:51.787612Z","iopub.status.idle":"2022-12-30T16:54:16.042061Z","shell.execute_reply.started":"2022-12-30T16:48:51.787228Z","shell.execute_reply":"2022-12-30T16:54:16.041225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Model","metadata":{}},{"cell_type":"code","source":"# 4classes classification 100 epochs\n#Maximum validation achieved is 63.888888888888886, after epoch: 45\n\n# 3 classes classification 100 epochs\n#Maximum validation achieved is 81.48148148148148, after epoch: 22\n\n# 4 classes 3 classes classification model transfer and fine tune for 4 classes\n# Maximum validation achieved is 63.888888888888886, after epoch: 8\n","metadata":{"execution":{"iopub.status.busy":"2022-12-30T16:54:16.043605Z","iopub.execute_input":"2022-12-30T16:54:16.043886Z","iopub.status.idle":"2022-12-30T16:54:16.049535Z","shell.execute_reply.started":"2022-12-30T16:54:16.043841Z","shell.execute_reply":"2022-12-30T16:54:16.048623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = torch.linspace(0, epochs-1)\nplt.plot(epoch_range, train_accuracy)\nplt.plot(epoch_range, val_accuracy)\nplt.savefig('accuracy_4_classes.png')\nplt.show()\n\n\nplt.plot(epoch_range, train_loss)\nplt.plot(epoch_range, val_loss)\nplt.savefig('Loss_4_classes.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-30T17:06:58.243369Z","iopub.execute_input":"2022-12-30T17:06:58.243708Z","iopub.status.idle":"2022-12-30T17:06:58.589707Z","shell.execute_reply.started":"2022-12-30T17:06:58.243656Z","shell.execute_reply":"2022-12-30T17:06:58.588929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Maximum validation achieved is {max(val_accuracy)}, after epoch: {val_accuracy.index(max(val_accuracy))}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-30T16:54:16.396346Z","iopub.execute_input":"2022-12-30T16:54:16.396916Z","iopub.status.idle":"2022-12-30T16:54:16.402971Z","shell.execute_reply.started":"2022-12-30T16:54:16.396645Z","shell.execute_reply":"2022-12-30T16:54:16.402155Z"},"trusted":true},"execution_count":null,"outputs":[]}]}